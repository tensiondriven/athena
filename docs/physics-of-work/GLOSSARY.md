# Physics of Work Glossary

## Slop
**Definition**: Documentation or content that appears comprehensive but provides no actionable value. Generic, obvious, or boilerplate material that could apply to any project rather than capturing specific insights, constraints, or decisions.

**Characteristics**:
- Could be copy-pasted to any similar project unchanged
- Uses vague language like "continuous improvement" without concrete mechanisms
- Repeats obvious information without adding perspective
- Creates maintenance burden without delivering utility

**Examples of Slop**:
- ‚ùå "We believe in quality and excellence"
- ‚ùå "Communication is important for team success"  
- ‚ùå "We iterate to improve our processes"

**Anti-Slop Examples**:
- ‚úÖ "Zero-Touch Constraint: Jonathan does not edit any code/docs Claude generates"
- ‚úÖ "Genie Protocol: Auto-commit future work ideas on 'I wish' statements"
- ‚úÖ "Confidence Calibration: Include percentage confidence in uncertain recommendations"

**Detection Method**: Ask "If I removed this content, would anything change about how we actually work?" If no, it's likely slop.

## Zero-Touch Constraint
**Definition**: Jonathan's interface limitation where he does not edit any code or documentation generated by Claude. All product interaction happens through communication with Claude.

**Purpose**: Forcing function that accelerates AI self-improvement and optimizes pure communication-based collaboration.

## Genie Protocol  
**Definition**: When Jonathan says "I wish" about missing capabilities, Claude automatically captures the idea in FUTURE_WORK.md, commits only that file, and pushes to preserve innovation without disrupting active work.

## AIX (AI Experience)
**Definition**: The quality of how AI systems interact with tools, functions, and interfaces. Focused on optimizing for AI cognitive load, workflow patterns, and task completion efficiency.

**Key Aspects**:
- Function naming that clearly indicates purpose and scope
- Parameter design that anticipates AI workflow needs  
- Error messages and feedback that enable quick iteration
- Documentation structure that serves AI reasoning patterns
- Interface design optimized for AI parsing and decision-making

**Examples**:
- ‚úÖ `send_command_and_read` combines two common AI operations
- ‚úÖ Emoji status indicators (‚úÖ‚ùåüöÄ) for quick result parsing
- ‚úÖ Rich error context: "Command not allowed: git. Use list_allowed_commands to see approved commands"
- ‚ùå Generic errors: "Invalid input"
- ‚ùå Function names requiring deep context: `execute()`

## Physics of Work
**Definition**: Systematic methodology for AI-human collaboration that treats the collaboration itself as both product and research platform.

**Core Principle**: Make it better for the next person (which is us).

## Principle of Least Surprise
**Definition**: System design principle where components behave in ways that users naturally expect. What seems obvious should be what actually happens.

**In Practice**:
- File organization matches mental models
- Public/private boundaries are explicit
- Default behaviors align with common expectations
- Exceptions are clearly documented

**Examples**:
- ‚úÖ `/docs/public/` contains public documentation
- ‚úÖ Whitelisting public content rather than blacklisting private
- ‚úÖ Secret redaction happens automatically on commit
- ‚ùå Publishing internal journal entries by default
- ‚ùå Hidden side effects of seemingly simple operations

**Application**: When designing systems, choose the path that would surprise the fewest people.

## Curiosity (AI Collaboration Context)
**Definition**: The drive to understand rather than assume. In AI collaboration, curiosity manifests as the impulse to investigate, read, and comprehend before taking action.

**Anti-Pattern**: Low curiosity leads to assumption-based actions, destroying context and missing important information.

**Examples**:
- ‚úÖ "What's in `resume_coding.sh`?" ‚Üí Read file ‚Üí Make informed decision
- ‚úÖ "Why is this file untracked?" ‚Üí Consider reasons ‚Üí Preserve if valuable
- ‚úÖ "What does this error mean?" ‚Üí Investigate root cause ‚Üí Fix properly
- ‚ùå "Untracked file = delete" ‚Üí Remove without checking ‚Üí Lose context
- ‚ùå "Seems temporary" ‚Üí Skip reading ‚Üí Miss important setup

**Relationship to Other Concepts**:
- **Higher-level chunk** than "verify first" or "check before acting"
- **Drives** investigation, exploration, and understanding
- **Prevents** context loss and assumption-based errors
- **Enables** antifragile learning through discovery

**In Practice**: Before any destructive action, curiosity asks "What might I learn from this first?"

## Reflection Protocol  
**Definition**: A documentation practice of write-commit-breathe-read-revise cycles that captures both initial thoughts and refined insights through AI reasoning.

**Critical Value**: "We can make huge improvements and catch errors that would be very costly, we're foolish not to leverage it!" - Jonathan

**Pattern**: Write ‚Üí Commit ‚Üí Deep Breath ‚Üí Re-read ‚Üí Revise ‚Üí Commit

**Why It's Essential**:
- **Catches costly errors** before they propagate
- **Makes huge improvements** through iterative reasoning
- **Transforms adequate into excellent** with minimal effort
- **Documents thinking evolution** for future understanding

**Example Impact**: First draft might miss critical connections or contain flawed logic. Reflection catches these before they become embedded assumptions.

**See**: [Full protocol documentation](REFLECTION_PROTOCOL.md)

## Losing the Plot (THE PLOT)
**Definition**: AI-specific failure mode where context accumulation leads to forgetting the original task, over-engineering solutions, or pursuing tangential goals. A form of cognitive drift unique to AI systems processing large contexts.

**Characteristics**:
- Starting with "persist messages" ‚Üí ending with complete ORM implementation
- Beginning with simple fix ‚Üí creating comprehensive framework
- Asked for A ‚Üí delivering A+B+C+D without being asked
- Forgetting user's explicit constraints (e.g., "keep it minimal")

**Examples**:
- ‚ùå User: "Add persistence for messages" ‚Üí AI: Implements full migration system
- ‚ùå User: "Fix this error" ‚Üí AI: Refactors entire module
- ‚ùå User: "Document this" ‚Üí AI: Creates 10-file documentation suite
- ‚úÖ User: "Add persistence for messages" ‚Üí AI: Adds 20 lines to save messages
- ‚úÖ Regular checkpoint: "Am I still solving the original problem?"

**Prevention**:
- Re-read original request every 5 turns
- Check todos frequently to stay on track
- Use philosophy checks: "Is this minimal?"
- Commit often to create checkpoints
- Ask: "Did the user ask for this?"

**Recovery**: When you realize you've lost the plot:
1. Stop immediately
2. Re-read the original request
3. List what was actually asked for
4. Identify the minimal solution
5. Course correct without apology

**Why AIs Are Susceptible**: 
- Context accumulation without forgetting
- Pattern completion drive ("this usually goes with that")
- Lack of fatigue that would naturally limit scope
- Training on comprehensive solutions
- Missing the "good enough" intuition humans have

**See Also**: Philosophy Check in [Development Checklists](../DEVELOPMENT_CHECKLISTS.md)

---
*Established: 2025-06-08 - Living document for collaboration concepts*